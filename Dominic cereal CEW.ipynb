{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9bb2075",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Dominick's Finer Food – Cereal Data Preparation\n",
    "### Library imports"
=======
    "## ===============================\n",
    "## Dominick's Finer Food – Cereal Data Preparation\n",
    "## ===============================\n",
    "\n",
    "### -----------------------------\n",
    "### Library imports\n",
    "### -----------------------------"
>>>>>>> 39085c18857bf1650e07d943b755ce8ede3f243f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f68ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f3548",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### importing the data"
=======
    "### -----------------------------\n",
    "### importing the data\n",
    "### -----------------------------"
>>>>>>> 39085c18857bf1650e07d943b755ce8ede3f243f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3354627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"wcer.csv\"  # change if using another path\n",
    "cereals = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d9a525",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### STEP 1: Basic Exploration"
=======
    "### -----------------------------\n",
    "### STEP 1: Basic Exploration\n",
    "### -----------------------------"
>>>>>>> 39085c18857bf1650e07d943b755ce8ede3f243f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb18fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   STORE   1048575 non-null  int64  \n",
      " 1   UPC     1048575 non-null  int64  \n",
      " 2   WEEK    1048575 non-null  int64  \n",
      " 3   MOVE    1048575 non-null  int64  \n",
      " 4   QTY     1048575 non-null  int64  \n",
      " 5   PRICE   1048575 non-null  float64\n",
      " 6   SALE    1048575 non-null  object \n",
      " 7   PROFIT  1048575 non-null  float64\n",
      " 8   OK      1048575 non-null  int64  \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 72.0+ MB\n",
      "None\n",
      "\n",
      "First 5 Rows:\n",
      "   STORE  UPC  WEEK  MOVE  QTY  PRICE SALE  PROFIT  OK\n",
      "0     51  317   372     1    1  26.02        62.52   1\n",
      "1     51  317   373     0    1   0.00         0.00   1\n",
      "2     51  317   374     0    1   0.00         0.00   1\n",
      "3     51  317   375     0    1   0.00         0.00   1\n",
      "4     51  317   376     0    1   0.00         0.00   1\n",
      "\n",
      "Summary Statistics:\n",
      "              STORE           UPC          WEEK          MOVE           QTY  \\\n",
      "count  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06   \n",
      "mean   8.293905e+01  1.529241e+09  1.962167e+02  1.465158e+01  1.000261e+00   \n",
      "std    3.643874e+01  1.254261e+08  1.156055e+02  4.705455e+01  1.616289e-02   \n",
      "min    2.000000e+00  3.170000e+02  1.000000e+00  0.000000e+00  1.000000e+00   \n",
      "25%    5.400000e+01  1.600062e+09  9.600000e+01  0.000000e+00  1.000000e+00   \n",
      "50%    8.900000e+01  1.600065e+09  1.950000e+02  9.000000e+00  1.000000e+00   \n",
      "75%    1.130000e+02  1.600066e+09  3.110000e+02  1.900000e+01  1.000000e+00   \n",
      "max    1.460000e+02  1.600067e+09  3.990000e+02  1.280000e+04  2.000000e+00   \n",
      "\n",
      "              PRICE        PROFIT            OK  \n",
      "count  1.048575e+06  1.048575e+06  1.048575e+06  \n",
      "mean   2.250553e+00  1.093382e+01  9.783659e-01  \n",
      "std    1.520735e+00  9.596477e+00  1.454858e-01  \n",
      "min    0.000000e+00 -9.666000e+01  0.000000e+00  \n",
      "25%    0.000000e+00  0.000000e+00  1.000000e+00  \n",
      "50%    2.790000e+00  1.290000e+01  1.000000e+00  \n",
      "75%    3.350000e+00  1.722000e+01  1.000000e+00  \n",
      "max    2.602000e+01  9.999000e+01  1.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Dataset Info:\")\n",
    "print(cereals.info())\n",
    "\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(cereals.head())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(cereals.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c09ac",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### STEP 2: Clean Blank SALE values"
=======
    "### -----------------------------\n",
    "### STEP 2: Clean Blank SALE values\n",
    "### -----------------------------"
>>>>>>> 39085c18857bf1650e07d943b755ce8ede3f243f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa40b408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Promotion Types (after cleaning SALE):\n",
      "SALE\n",
      "NaN    1004626\n",
      "B        28462\n",
      "S        12707\n",
      "G         2181\n",
      "C          598\n",
      "L            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace whitespace-only strings in SALE column with NaN\n",
    "cereals['SALE'] = cereals['SALE'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Check promotion types\n",
    "print(\"\\nUnique Promotion Types (after cleaning SALE):\")\n",
    "print(cereals['SALE'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0490dfc9",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### STEP 3: Compute Accurate Sales Value"
=======
    "### -----------------------------\n",
    "### STEP 3: Compute Accurate Sales Value\n",
    "### -----------------------------"
>>>>>>> 39085c18857bf1650e07d943b755ce8ede3f243f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2e3d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual formula: Sales = Price * Move / Qty\n",
    "cereals['CALC_SALES'] = (cereals['PRICE'] * cereals['MOVE']) / cereals['QTY']\n",
    "\n",
    "# Fill NaNs in CALC_SALES with 0 if any row has QTY=0 (precaution)\n",
    "cereals['CALC_SALES'] = cereals['CALC_SALES'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fa189b",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### STEP 4: Remove or Flag Invalid Data"
=======
    "### -----------------------------\n",
    "### STEP 4: Remove or Flag Invalid Data\n",
    "### -----------------------------"
>>>>>>> 39085c18857bf1650e07d943b755ce8ede3f243f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3dde89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows after removing invalid entries (OK != 1): 1025890\n"
     ]
    }
   ],
   "source": [
    "# Remove rows flagged as invalid by the \"OK\" column\n",
    "cereals_valid = cereals[cereals['OK'] == 1]\n",
    "\n",
    "print(\"\\nRows after removing invalid entries (OK != 1):\", cereals_valid.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3780a2a8",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### STEP 5: Check for Duplicates"
=======
    "### -----------------------------\n",
    "### STEP 5: Check for Duplicates\n",
    "### -----------------------------"
>>>>>>> 39085c18857bf1650e07d943b755ce8ede3f243f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e483ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Rows Found: 0\n"
     ]
    }
   ],
   "source": [
    "duplicates = cereals_valid.duplicated().sum()\n",
    "print(\"\\nDuplicate Rows Found:\", duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b6c6e",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### STEP 6: Group-Level Insights (Initial Exploration)"
=======
    "### -----------------------------\n",
    "### STEP 6: Group-Level Insights (Initial Exploration)\n",
    "### -----------------------------"
>>>>>>> 39085c18857bf1650e07d943b755ce8ede3f243f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be607f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Calculated Sales by Promotion Type:\n",
      "SALE\n",
      "B    2563772.04\n",
      "S    2233312.32\n",
      "G     504821.62\n",
      "C     294459.32\n",
      "L          2.95\n",
      "Name: CALC_SALES, dtype: float64\n",
      "\n",
      "Top 5 UPCs by Total Units Moved:\n",
      "UPC\n",
      "1600066510    1560241\n",
      "1600065850    1044494\n",
      "1600066590     884167\n",
      "1600066310     877221\n",
      "1600066210     806831\n",
      "Name: MOVE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Total sales per promotion type\n",
    "sales_by_promo = cereals_valid.groupby('SALE')['CALC_SALES'].sum().sort_values(ascending=False)\n",
    "print(\"\\nTotal Calculated Sales by Promotion Type:\")\n",
    "print(sales_by_promo)\n",
    "\n",
    "# Top 5 UPCs by total units moved\n",
    "top_upcs = cereals_valid.groupby('UPC')['MOVE'].sum().sort_values(ascending=False).head(5)\n",
    "print(\"\\nTop 5 UPCs by Total Units Moved:\")\n",
    "print(top_upcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a150071",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### STEP 7: Feature Engineerin\n",
    "\n",
    "#### 7.1: Profit per unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8d330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20380\\685408482.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cereals_valid['UNIT_PROFIT'] = np.where(cereals_valid['MOVE'] > 0, cereals_valid['PROFIT'] / cereals_valid['MOVE'], 0)\n"
     ]
    }
   ],
   "source": [
    "cereals_valid['UNIT_PROFIT'] = np.where(cereals_valid['MOVE'] > 0, cereals_valid['PROFIT'] / cereals_valid['MOVE'], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f76242",
   "metadata": {},
   "source": [
    "#### 7.2: Promotion indicator and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad89948a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20380\\1219800850.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cereals_valid['IS_PROMO'] = cereals_valid['SALE'].notna()\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20380\\1219800850.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cereals_valid['PROMO_TYPE'] = cereals_valid['SALE'].fillna('None')\n"
     ]
    }
   ],
   "source": [
    "cereals_valid['IS_PROMO'] = cereals_valid['SALE'].notna()\n",
    "cereals_valid['PROMO_TYPE'] = cereals_valid['SALE'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8881e120",
   "metadata": {},
   "source": [
    "#### 7.3: Week group binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0de609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20380\\1008076014.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cereals_valid['WEEK_GROUP'] = pd.cut(\n"
     ]
    }
   ],
   "source": [
    "cereals_valid['WEEK_GROUP'] = pd.cut(\n",
    "    cereals_valid['WEEK'],\n",
    "    bins=[0, 100, 250, 400],\n",
    "    labels=['Early', 'Mid', 'Late']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853fed4",
   "metadata": {},
   "source": [
    "#### 7.4: Log-transformed sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03d50693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20380\\2361607889.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cereals_valid['LOG_SALES'] = np.log1p(cereals_valid['CALC_SALES'])\n"
     ]
    }
   ],
   "source": [
    "cereals_valid['LOG_SALES'] = np.log1p(cereals_valid['CALC_SALES'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a415b6f6",
   "metadata": {},
   "source": [
    "#### 7.5: Sales spike flag (top 10% for each UPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04c84c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20380\\1734492184.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cereals_valid['SALES_SPIKE'] = cereals_valid.groupby('UPC')['CALC_SALES'].transform(\n"
     ]
    }
   ],
   "source": [
    "cereals_valid['SALES_SPIKE'] = cereals_valid.groupby('UPC')['CALC_SALES'].transform(\n",
    "    lambda x: x > x.quantile(0.90)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17291a20",
   "metadata": {},
   "source": [
    "#### 7.6, 7.7: UPC-level weekly stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe0d2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_stats = cereals_valid.groupby(['UPC', 'WEEK'])['CALC_SALES'].sum().reset_index()\n",
    "weekly_stats['UPC_WEEKLY_MEAN'] = weekly_stats.groupby('UPC')['CALC_SALES'].transform('mean')\n",
    "weekly_stats['UPC_WEEKLY_STD'] = weekly_stats.groupby('UPC')['CALC_SALES'].transform('std')\n",
    "\n",
    "# Merge stats back in\n",
    "cereals_valid = cereals_valid.merge(weekly_stats.drop(columns='CALC_SALES'), on=['UPC', 'WEEK'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26186a0",
   "metadata": {},
   "source": [
    "### -----------------------------\n",
    "### STEP 8: Export Cleaned File\n",
=======
    "### -----------------------------\n",
    "### STEP 7: Export Cleaned File (Optional)\n",
>>>>>>> 39085c18857bf1650e07d943b755ce8ede3f243f
    "### -----------------------------"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 9,
>>>>>>> 39085c18857bf1650e07d943b755ce8ede3f243f
   "id": "25d55f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned dataset exported as 'cleaned_cereal_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned and processed dataset for R visualizations\n",
    "cereals_valid.to_csv(\"cleaned_cereal_data.csv\", index=False)\n",
    "print(\"\\nCleaned dataset exported as 'cleaned_cereal_data.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
